{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d3d0ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb5f82e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded keys: ['ksp', 'sens', 'theta', 'lam', 'val', 'omega', 'split_seed']\n",
      "P=20, C=24, X=160, Y=128, Z=72\n",
      "ksp dtype: torch.complex64  sens dtype: torch.complex64\n",
      "θ/λ/val/Ω shapes: (20, 128, 72) (20, 128, 72) (20, 128, 72) (20, 128, 72)\n",
      "cues_2d shape: (20, 256, 72)  (P,2,Y,Z)\n",
      "mean|Σ|S|^2 - 1| ≈ 0.000000e+00\n",
      "Broadcast masks: th_b/la_b/val_b/om_b → (20, 1, 1, 128, 72)\n"
     ]
    }
   ],
   "source": [
    "# Step 1 — Data I/O + prep (device-ready)\n",
    "path_npz = \"scan20_splits.npz\"\n",
    "device   = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def load_step1(npz_path, device):\n",
    "    data = np.load(npz_path, allow_pickle=False)\n",
    "    # raw numpy\n",
    "    ksp_np  = data[\"ksp\"]    # (P,C,X,Y,Z) complex64\n",
    "    sens_np = data[\"sens\"]   # (C,X,Y,Z)   complex64\n",
    "    th_np   = data[\"theta\"]  # (P,Y,Z)\n",
    "    la_np   = data[\"lam\"]    # (P,Y,Z)\n",
    "    va_np   = data[\"val\"]    # (P,Y,Z)\n",
    "    om_np   = data[\"omega\"]  # (P,Y,Z)\n",
    "    seed    = int(data[\"split_seed\"])\n",
    "\n",
    "    P, C, X, Y, Z = ksp_np.shape\n",
    "\n",
    "    # to torch (on device)\n",
    "    ksp_t  = torch.from_numpy(ksp_np).to(device)          # complex64\n",
    "    sens_t = torch.from_numpy(sens_np).to(device)         # complex64\n",
    "\n",
    "    # masks → bool on device\n",
    "    theta_t = torch.from_numpy(th_np.astype(np.bool_)).to(device)\n",
    "    lam_t   = torch.from_numpy(la_np.astype(np.bool_)).to(device)\n",
    "    val_t   = torch.from_numpy(va_np.astype(np.bool_)).to(device)\n",
    "    omega_t = torch.from_numpy(om_np.astype(np.bool_)).to(device)\n",
    "\n",
    "    # broadcast masks: (P,1,1,Y,Z)\n",
    "    def bmask(m): return m.view(P, 1, 1, Y, Z)\n",
    "    th_b = bmask(theta_t)\n",
    "    la_b = bmask(lam_t)\n",
    "    val_b= bmask(val_t)\n",
    "    om_b = bmask(omega_t)\n",
    "\n",
    "    # temporal cues (sin/cos per phase) → (P,2,Y,Z) float32\n",
    "    phases = torch.arange(P, device=device, dtype=torch.float32)\n",
    "    ang    = 2.0 * math.pi * phases / float(P)            # (P,)\n",
    "    s      = torch.sin(ang).view(P,1,1,1)                 # (P,1,1,1)\n",
    "    c      = torch.cos(ang).view(P,1,1,1)                 # (P,1,1,1)\n",
    "    ones_yz= torch.ones((1,1,Y,Z), device=device, dtype=torch.float32)\n",
    "    sin_map= (s * ones_yz).squeeze(1)                     # (P,1,Y,Z)\n",
    "    cos_map= (c * ones_yz).squeeze(1)                     # (P,1,Y,Z)\n",
    "    cues_2d= torch.cat([sin_map, cos_map], dim=1).contiguous()  # (P,2,Y,Z)\n",
    "\n",
    "    # quick summary\n",
    "    s2 = (sens_t.conj()*sens_t).real.sum(dim=0).mean().item()\n",
    "    print(f\"Loaded keys: {list(data.keys())}\")\n",
    "    print(f\"P={P}, C={C}, X={X}, Y={Y}, Z={Z}\")\n",
    "    print(f\"ksp dtype: {ksp_t.dtype}  sens dtype: {sens_t.dtype}\")\n",
    "    print(f\"θ/λ/val/Ω shapes: {tuple(theta_t.shape)} {tuple(lam_t.shape)} {tuple(val_t.shape)} {tuple(omega_t.shape)}\")\n",
    "    print(f\"cues_2d shape: {tuple(cues_2d.shape)}  (P,2,Y,Z)\")\n",
    "    print(f\"mean|Σ|S|^2 - 1| ≈ {abs(s2 - 1.0):.6e}\")\n",
    "    print(f\"Broadcast masks: th_b/la_b/val_b/om_b → {(P,1,1,Y,Z)}\")\n",
    "\n",
    "    bmasks = {\"theta\": th_b, \"lam\": la_b, \"val\": val_b, \"omega\": om_b}\n",
    "    return ksp_t, sens_t, bmasks, cues_2d, seed\n",
    "\n",
    "# run\n",
    "ksp_t, sens_t, bmasks, cues_2d, split_seed = load_step1(path_npz, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2112fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 — FFT & SENSE operators (3D, orthonormal)\n",
    "# --- centered 3D FFTs (no explicit shifts; data/masks assumed consistent) ---\n",
    "def fft3c(x: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"3D FFT with 'ortho' norm. x: (..., X, Y, Z) complex.\"\"\"\n",
    "    return torch.fft.fftn(x, dim=(-3, -2, -1), norm=\"ortho\")\n",
    "\n",
    "def ifft3c(x: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"3D iFFT with 'ortho' norm. x: (..., X, Y, Z) complex.\"\"\"\n",
    "    return torch.fft.ifftn(x, dim=(-3, -2, -1), norm=\"ortho\")\n",
    "\n",
    "# --- SENSE Encoding (A) and Adjoint (AH) ---\n",
    "def A(x_img: torch.Tensor, mask_yz: torch.Tensor, sens: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Forward encoding: x -> masked multi-coil k-space.\n",
    "      x_img: (X,Y,Z) complex\n",
    "      mask_yz: (1,1,Y,Z) bool/float (broadcast over C,X)\n",
    "      sens: (C,X,Y,Z) complex\n",
    "    Returns: (C,X,Y,Z) complex\n",
    "    \"\"\"\n",
    "    coil_img = sens * x_img.unsqueeze(0)            # (C,X,Y,Z)\n",
    "    ksp      = fft3c(coil_img)                      # (C,X,Y,Z)\n",
    "    return ksp * mask_yz                            # broadcast over C,X\n",
    "\n",
    "def AH(y_ksp: torch.Tensor, mask_yz: torch.Tensor, sens: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Adjoint: masked multi-coil k-space -> combined image.\n",
    "      y_ksp: (C,X,Y,Z) complex\n",
    "      mask_yz: (1,1,Y,Z) bool/float\n",
    "      sens: (C,X,Y,Z) complex\n",
    "    Returns: (X,Y,Z) complex\n",
    "    \"\"\"\n",
    "    y_mask = y_ksp * mask_yz                        # (C,X,Y,Z)\n",
    "    coil_img = ifft3c(y_mask)                       # (C,X,Y,Z)\n",
    "    x_img = (coil_img * sens.conj()).sum(dim=0)     # (X,Y,Z)\n",
    "    return x_img\n",
    "\n",
    "# --- Convenience: zero-filled SENSE adjoint for a single phase ---\n",
    "def zf_image(ksp_p: torch.Tensor, mask_yz_p: torch.Tensor, sens: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Zero-filled reconstruction (adjoint of A) for one phase.\n",
    "      ksp_p:  (C,X,Y,Z) complex\n",
    "      mask_yz_p: (1,1,Y,Z) bool/float\n",
    "      sens:   (C,X,Y,Z) complex\n",
    "    Returns: (X,Y,Z) complex\n",
    "    \"\"\"\n",
    "    return AH(ksp_p, mask_yz_p, sens)\n",
    "\n",
    "# # --- Quick sanity check (uses tensors from Step 1) ---\n",
    "# with torch.no_grad():\n",
    "#     P, C, X, Y, Z = ksp_t.shape\n",
    "#     p = 0\n",
    "#     y_p   = ksp_t[p]                 # (C,X,Y,Z)\n",
    "#     m_th  = bmasks[\"theta\"][p]       # (1,1,Y,Z)\n",
    "#     x_zf  = zf_image(y_p, m_th, sens_t)      # (X,Y,Z)\n",
    "#     y_hat = A(x_zf, m_th, sens_t)            # (C,X,Y,Z)\n",
    "\n",
    "#     print(f\"[Check] x_zf: {tuple(x_zf.shape)}, y_hat: {tuple(y_hat.shape)}  dtypes={x_zf.dtype}/{y_hat.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a10c8b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kspace_metrics(y_hat: torch.Tensor,\n",
    "                   y: torch.Tensor,\n",
    "                   mask_acq: torch.Tensor) -> tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Compute k-space metrics:\n",
    "      - MSE over acquired samples (Ω_MSE)\n",
    "      - Energy over unacquired samples (Ω^c_E)\n",
    "\n",
    "    Args:\n",
    "        y_hat    : (C, X, Y, Z) complex — predicted k-space\n",
    "        y        : (C, X, Y, Z) complex — reference/true k-space\n",
    "        mask_acq : (Y, Z) or (1,1,Y,Z), bool or float — acquisition mask Ω\n",
    "\n",
    "    Returns:\n",
    "        (omse, oce) as floats\n",
    "          omse = mean squared error over Ω\n",
    "          oce  = mean squared magnitude over Ω^c\n",
    "    \"\"\"\n",
    "    # Ensure mask is float and broadcastable to (C,X,Y,Z)\n",
    "    if mask_acq.ndim == 2:\n",
    "        m = mask_acq[None, None, ...]\n",
    "    elif mask_acq.ndim == 4:\n",
    "        m = mask_acq\n",
    "    else:\n",
    "        raise ValueError(\"mask_acq must be (Y,Z) or (1,1,Y,Z)\")\n",
    "    m = m.to(dtype=torch.float32, device=y_hat.device)\n",
    "\n",
    "    # Squared magnitudes (real scalars)\n",
    "    diff    = y_hat - y\n",
    "    sq_diff = diff.real.pow(2) + diff.imag.pow(2)     # (C,X,Y,Z)\n",
    "    sq_pred = y_hat.real.pow(2) + y_hat.imag.pow(2)   # (C,X,Y,Z)\n",
    "\n",
    "    # Complement mask\n",
    "    one_m = 1.0 - m\n",
    "\n",
    "    # Normalize by element counts across C and X\n",
    "    C, X = y_hat.shape[0], y_hat.shape[1]\n",
    "    num_acq = (m.sum() * (C * X)).item()\n",
    "    num_un  = (one_m.sum() * (C * X)).item()\n",
    "\n",
    "    omse = ((sq_diff * m).sum().item()   / max(num_acq, 1.0)) if num_acq > 0 else float('nan')\n",
    "    oce  = ((sq_pred * one_m).sum().item() / max(num_un,  1.0)) if num_un  > 0 else 0.0\n",
    "    return omse, oce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad5bfb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBNAct(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, k=3):\n",
    "        super().__init__()\n",
    "        p = k//2\n",
    "        self.conv = nn.Conv2d(in_ch, out_ch, k, padding=p)\n",
    "        self.gn   = nn.GroupNorm(num_groups=8, num_channels=out_ch)\n",
    "        self.act  = nn.LeakyReLU(0.1, inplace=True)\n",
    "    def forward(self, x):\n",
    "        return self.act(self.gn(self.conv(x)))\n",
    "\n",
    "class UNetBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.c1 = ConvBNAct(in_ch,  out_ch)\n",
    "        self.c2 = ConvBNAct(out_ch, out_ch)\n",
    "    def forward(self, x):\n",
    "        x = self.c1(x)\n",
    "        x = self.c2(x)\n",
    "        return x\n",
    "\n",
    "class Pseudo3DUNet2p5D(nn.Module):\n",
    "    \"\"\"\n",
    "    Input:  (B, 2*k, H, W) — k neighboring slices, real/imag stacked as channels\n",
    "    Output: (B, 2,   H, W) — residual for center slice (real, imag)\n",
    "    \"\"\"\n",
    "    def __init__(self, in_ch=10, base=32, out_ch=2, residual_scale=0.1):\n",
    "        super().__init__()\n",
    "        self.enc1 = UNetBlock(in_ch,   base)\n",
    "        self.enc2 = UNetBlock(base,    base*2)\n",
    "        self.enc3 = UNetBlock(base*2,  base*4)\n",
    "\n",
    "        self.down1 = nn.Conv2d(base,   base,   3, stride=2, padding=1)\n",
    "        self.down2 = nn.Conv2d(base*2, base*2, 3, stride=2, padding=1)\n",
    "\n",
    "        self.dec2 = UNetBlock(base*4 + base*2, base*2)\n",
    "        self.dec1 = UNetBlock(base*2 + base,   base)\n",
    "\n",
    "        self.out  = nn.Conv2d(base, out_ch, 1)\n",
    "        self.res_scale = residual_scale\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        e1 = self.enc1(x)                  # (B, B, H, W)\n",
    "        x  = self.down1(e1)                # (B, B, H/2, W/2)\n",
    "        e2 = self.enc2(x)                  # (B, 2B, H/2, W/2)\n",
    "        x  = self.down2(e2)                # (B, 2B, H/4, W/4)\n",
    "        e3 = self.enc3(x)                  # (B, 4B, H/4, W/4)\n",
    "\n",
    "        # Decoder\n",
    "        x  = F.interpolate(e3, scale_factor=2, mode='bilinear', align_corners=False)\n",
    "        x  = torch.cat([x, e2], dim=1)\n",
    "        x  = self.dec2(x)\n",
    "\n",
    "        x  = F.interpolate(x, scale_factor=2, mode='bilinear', align_corners=False)\n",
    "        x  = torch.cat([x, e1], dim=1)\n",
    "        x  = self.dec1(x)\n",
    "\n",
    "        out = self.out(x)\n",
    "        return out * self.res_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "973495c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @torch.no_grad()\n",
    "def _neighbor_indices_X(X: int, K: int, x0: int):\n",
    "    \"\"\"Clamp-replicate neighbor indices along X for center x0.\"\"\"\n",
    "    r = K // 2\n",
    "    idxs = [min(max(x0 + d, 0), X - 1) for d in range(-r, r + 1)]\n",
    "    return idxs  # length K\n",
    "\n",
    "def _make_25d_stack(x_img: torch.Tensor, K: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Build 2.5D stack over (Y,Z) with batch=X:\n",
    "      x_img: (X,Y,Z) complex\n",
    "      return: (X, 2*K, Y, Z) float  [real/imag per neighbor slice]\n",
    "    \"\"\"\n",
    "    assert x_img.ndim == 3 and torch.is_complex(x_img)\n",
    "    X, Y, Z = x_img.shape\n",
    "    r = K // 2\n",
    "\n",
    "    # Collect per-center stacks\n",
    "    stacks = []\n",
    "    for x0 in range(X):\n",
    "        idxs = _neighbor_indices_X(X, K, x0)      # length K\n",
    "        nb   = x_img[idxs, ...]                   # (K, Y, Z) complex\n",
    "        ch   = torch.stack([nb.real, nb.imag], dim=1)  # (K, 2, Y, Z)\n",
    "        ch   = ch.reshape(K * 2, Y, Z)                 # (2K, Y, Z)\n",
    "        stacks.append(ch)\n",
    "    inp = torch.stack(stacks, dim=0)              # (X, 2K, Y, Z)\n",
    "    return inp\n",
    "\n",
    "def apply_prior_25d_cued(prior_25d, x_img: torch.Tensor, cues_yz: torch.Tensor, K: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Apply temporal-cued 2.5D prior on (Y,Z) planes, batched over X.\n",
    "      prior_25d: Pseudo3DUNet2p5D(in_ch=2*K + 2)\n",
    "      x_img: (X,Y,Z) complex\n",
    "      cues_yz: (2, Y, Z) float  [sin, cos] for this phase\n",
    "      K: odd number of through-plane neighbors (e.g., 3, 5)\n",
    "    Returns: residual r (X,Y,Z) complex\n",
    "    \"\"\"\n",
    "    X, Y, Z = x_img.shape\n",
    "    stack_25d = _make_25d_stack(x_img, K)                  # (X, 2K, Y, Z), float\n",
    "    cues = cues_yz.unsqueeze(0).expand(X, -1, -1, -1)      # (X, 2,  Y, Z)\n",
    "\n",
    "    inp = torch.cat([stack_25d, cues], dim=1)              # (X, 2K+2, Y, Z)\n",
    "    out = prior_25d(inp)                                   # (X, 2,    Y, Z) float\n",
    "    r   = torch.complex(out[:, 0], out[:, 1])              # (X, Y, Z) complex\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47fb7426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --- Fix cues shape: (P, 2*Y, Z) -> (P, 2, Y, Z) ---\n",
    "# P, Cx, Z = cues_2d.shape            # currently (P, 2*Y, Z)\n",
    "# Y = Cx // 2\n",
    "# assert Cx == 2 * Y, \"Expected second dim to be 2*Y\"\n",
    "\n",
    "# sin_c = cues_2d[:, :Y, :].contiguous()\n",
    "# cos_c = cues_2d[:, Y:, :].contiguous()\n",
    "# cues_2d_fixed = torch.stack([sin_c, cos_c], dim=1)   # (P, 2, Y, Z)\n",
    "\n",
    "# # device/dtype alignment\n",
    "# cues_2d_fixed = cues_2d_fixed.to(ksp_t.device).float()\n",
    "\n",
    "# # --- Re-run the prior sanity check (same K and tmp prior) ---\n",
    "# p = 7\n",
    "# K = 3\n",
    "# prior_tmp = Pseudo3DUNet2p5D(in_ch=2*K + 2, base=16, out_ch=2, residual_scale=0.1).eval().to(ksp_t.device)\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     x_zf  = AH(ksp_t[p], bmasks['theta'][p], sens_t)            # (X,Y,Z) complex\n",
    "#     cues_p = cues_2d_fixed[p]                        # (2,Y,Z) float\n",
    "#     r = apply_prior_25d_cued(prior_tmp, x_zf, cues_p, K)  # (X,Y,Z) complex\n",
    "#     print(f\"[Sanity] x_zf={tuple(x_zf.shape)}  r={tuple(r.shape)}  dtype={r.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2b0f08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- minimal complex-safe CG for (A^H Ω A + λI) x = rhs ----\n",
    "# @torch.no_grad()\n",
    "def cg_solve(rhs, th_mask, sens, lam, x0=None, iters=8, tol=1e-6):\n",
    "    \"\"\"\n",
    "    rhs: (X,Y,Z) complex\n",
    "    th_mask: (1,1,Y,Z) bool/0-1\n",
    "    sens: (C,X,Y,Z) complex\n",
    "    lam: scalar float\n",
    "    \"\"\"\n",
    "    def M(x):\n",
    "        Ax  = A(x, th_mask, sens)\n",
    "        AHx = AH(Ax, th_mask, sens)\n",
    "        return AHx + lam * x\n",
    "\n",
    "    x = rhs.clone() if x0 is None else x0.clone()\n",
    "    r = rhs - M(x)\n",
    "    p = r.clone()\n",
    "    rs_old = (r.conj() * r).real.sum()\n",
    "\n",
    "    for _ in range(iters):\n",
    "        Ap = M(p)\n",
    "        denom = (p.conj() * Ap).real.sum().clamp_min(1e-20)\n",
    "        alpha = (rs_old / denom)\n",
    "        x = x + alpha * p\n",
    "        r = r - alpha * Ap\n",
    "        rs_new = (r.conj() * r).real.sum()\n",
    "        if torch.sqrt(rs_new) < tol * torch.sqrt((rhs.conj()*rhs).real.sum().clamp_min(1e-20)):\n",
    "            break\n",
    "        beta = rs_new / rs_old\n",
    "        p = r + beta * p\n",
    "        rs_old = rs_new\n",
    "    return x\n",
    "\n",
    "# ---- single-phase unrolled forward with cues ----\n",
    "# @torch.no_grad()\n",
    "# def unroll_one_phase_with_cues(prior_25d, p, K=3, lam=3e-2, unroll=5, iters=8, tol=1e-6, device=\"cuda\"):\n",
    "#     \"\"\"\n",
    "#     Returns: x (X,Y,Z) complex, and metrics (Ω_MSE, Ωc_E)\n",
    "#     \"\"\"\n",
    "#     # data for this phase\n",
    "#     y_full = ksp_t[p]                     # (C,X,Y,Z) complex\n",
    "#     m_th   = bmasks['theta'][p]                      # (1,1,Y,Z)\n",
    "#     y      = y_full * m_th                # acquired-only\n",
    "#     Ah_y   = AH(y, m_th, sens_t)          # (X,Y,Z)\n",
    "\n",
    "#     # ZF init\n",
    "#     x = Ah_y.clone()\n",
    "\n",
    "#     # cues for this phase: (2,Y,Z) float\n",
    "#     cues_p = cues_2d_fixed[p]             # from your fixed cues tensor (P,2,Y,Z)\n",
    "\n",
    "#     # unroll\n",
    "#     for _ in range(unroll):\n",
    "#         r   = apply_prior_25d_cued(prior_25d, x, cues_p, K)   # (X,Y,Z) complex residual\n",
    "#         x_t = x + r                                           # proximal target\n",
    "#         rhs = Ah_y + lam * x_t\n",
    "#         x   = cg_solve(rhs, m_th, sens_t, lam, x0=x, iters=iters, tol=tol)\n",
    "\n",
    "#     # k-space prediction and metrics\n",
    "#     y_hat = A(x, m_th, sens_t)      # predicted k-space\n",
    "#     omse, oce = kspace_metrics(y_hat, y_full, m_th)\n",
    "\n",
    "#     return x, omse, oce\n",
    "\n",
    "# # ---- quick demo on one phase (e.g., p=7) ----\n",
    "# p_demo = 7\n",
    "# lam_demo = 3e-2\n",
    "# x_rec, omse, oce = unroll_one_phase_with_cues(\n",
    "#     prior_25d=prior_tmp, p=p_demo, K=3, lam=lam_demo, unroll=3, iters=8, tol=1e-6,\n",
    "#     device=ksp_t.device.type\n",
    "# )\n",
    "# print(f\"[phase {p_demo+1:02d}] Ω_MSE={omse:.3e}  Ωc_E={oce:.3e}  | x={tuple(x_rec.shape)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "201996e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kspace_l1_l2_loss(y_pred, y_true, alpha=0.5, eps=1e-6):\n",
    "    diff = y_pred - y_true\n",
    "    mag  = torch.abs(diff)\n",
    "    l1   = mag.mean()\n",
    "    l2   = (mag**2).mean()\n",
    "    return alpha*l1 + (1-alpha)*l2\n",
    "\n",
    "def solve_cg(rhs, mask, sens, lam, iters, tol, x0=None):\n",
    "    out = cg_solve(rhs, mask, sens, lam, iters=iters, tol=tol, x0=x0)\n",
    "    return out[0] if isinstance(out, tuple) else out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0fabf66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cues_2d fixed shape: (20, 2, 128, 72)\n"
     ]
    }
   ],
   "source": [
    "# After loading data and defining (P, C, X, Y, Z) and device\n",
    "# cues_2d should be (P, 2, Y, Z). If it's (P, 2*Y, Z), reshape it.\n",
    "\n",
    "P, C, X, Y, Z = ksp_t.shape\n",
    "\n",
    "def normalize_cues_shape(cues_2d, Y, Z, device):\n",
    "    # ensure torch float on the right device\n",
    "    if isinstance(cues_2d, np.ndarray):\n",
    "        cues_2d = torch.from_numpy(cues_2d)\n",
    "    cues_2d = cues_2d.to(device=device, dtype=torch.float32)\n",
    "\n",
    "    # fix shape: (P, 2*Y, Z) -> (P, 2, Y, Z)\n",
    "    if cues_2d.ndim == 3 and cues_2d.shape[1] == 2*Y and cues_2d.shape[2] == Z:\n",
    "        P = cues_2d.shape[0]\n",
    "        cues_2d = cues_2d.view(P, 2, Y, Z).contiguous()\n",
    "\n",
    "    # sanity check\n",
    "    assert cues_2d.ndim == 4 and cues_2d.shape[1:] == (2, Y, Z), \\\n",
    "        f\"cues_2d must be (P,2,Y,Z), got {tuple(cues_2d.shape)}\"\n",
    "    return cues_2d\n",
    "\n",
    "# use it\n",
    "cues_2d = normalize_cues_shape(cues_2d, Y, Z, ksp_t.device)\n",
    "print(\"cues_2d fixed shape:\", tuple(cues_2d.shape))  # -> (P, 2, Y, Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ad5dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch_cued(\n",
    "    prior_25d, opt,\n",
    "    ksp, sens, bmasks, cues_2d,\n",
    "    A, AH, solve_cg, apply_prior_25d_cued, kspace_l1_l2_loss,\n",
    "    lam, K,\n",
    "    unroll=5, cg_iters=8, cg_tol=1e-3, alpha=0.5, device=\"cuda\"\n",
    "):\n",
    "    prior_25d.train()\n",
    "    P = ksp.shape[0]\n",
    "    order = torch.randperm(P, device=ksp.device)\n",
    "\n",
    "    running_loss = 0.0\n",
    "    steps = 0\n",
    "    gn_sum = 0.0\n",
    "\n",
    "    for p in order.tolist():\n",
    "        m_th  = bmasks[\"theta\"][p]          # (1,1,Y,Z) bool/float\n",
    "        m_L   = bmasks[\"lam\"][p]            # Λ mask for loss\n",
    "        cues  = cues_2d[p]                  # (2,Y,Z) float\n",
    "        y_th  = ksp[p] * m_th\n",
    "\n",
    "        # --- CG-SENSE init (Θ) ---\n",
    "        Ah_y  = AH(y_th, m_th, sens)                 # (X,Y,Z)\n",
    "        x     = solve_cg(Ah_y, m_th, sens, lam, cg_iters, cg_tol, x0=None)\n",
    "        x_dc = x.clone()\n",
    "\n",
    "        # --- Unrolled proximal gradient with cues ---\n",
    "        for _ in range(unroll):\n",
    "            r    = apply_prior_25d_cued(prior_25d, x_dc, cues, K)   # (X,Y,Z)\n",
    "            x_t  = x + 0.05 * r\n",
    "            rhs  = Ah_y + lam * x_t\n",
    "            x_dc    = solve_cg(rhs, m_th, sens, lam, cg_iters, cg_tol, x0=x_dc)\n",
    "\n",
    "        # --- Λ loss in k-space ---\n",
    "        y_L    = ksp[p] * m_L\n",
    "        y_hatL = A(x, m_L, sens)\n",
    "        loss   = kspace_l1_l2_loss(y_hatL, y_L, alpha)\n",
    "\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        running_loss += float(loss.item()); steps += 1\n",
    "\n",
    "        # grad norm (for logging)\n",
    "        gn = 0.0\n",
    "        for pmt in prior_25d.parameters():\n",
    "            if pmt.grad is not None:\n",
    "                gn += float(pmt.grad.detach().pow(2).sum().item())\n",
    "        gn_sum += gn**0.5\n",
    "\n",
    "    return {\"train_L\": running_loss / max(steps, 1), \"grad\": gn_sum/max(1,steps)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e740ef07",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def validate_all_phases_cued(\n",
    "    prior_25d,\n",
    "    ksp, sens, bmasks, cues_2d,\n",
    "    A, AH, solve_cg, apply_prior_25d_cued, kspace_l1_l2_loss, kspace_metrics,\n",
    "    lam, K,\n",
    "    unroll=5, cg_iters=25, cg_tol=1e-6, alpha=0.5\n",
    "):\n",
    "    prior_25d.eval()\n",
    "    P = ksp.shape[0]\n",
    "    losses, omse_list, oce_list = [], [], []\n",
    "\n",
    "    for p in range(P):\n",
    "        m_val = bmasks[\"val\"][p]            # (1,1,Y,Z)\n",
    "        cues  = cues_2d[p]                  # (2,Y,Z)\n",
    "\n",
    "        # CG-SENSE anchor with validation mask\n",
    "        y_val = ksp[p] * m_val\n",
    "        Ah_y  = AH(y_val, m_val, sens)\n",
    "        x     = solve_cg(Ah_y, m_val, sens, lam, cg_iters, cg_tol, x0=None)\n",
    "        x_dc = x.clone()\n",
    "\n",
    "        # Unroll with validation mask\n",
    "        for _ in range(unroll):\n",
    "            r    = apply_prior_25d_cued(prior_25d, x_dc, cues, K)   # (X,Y,Z)\n",
    "            # x_t  = x + r\n",
    "            x_t  = x + 0.05 * r\n",
    "            rhs  = Ah_y + lam * x_t\n",
    "            x_dc    = solve_cg(rhs, m_val, sens, lam, cg_iters, cg_tol, x0=x_dc)\n",
    "\n",
    "        # Λ loss on validation mask\n",
    "        y_hatV = A(x, m_val, sens)\n",
    "        losses.append(float(kspace_l1_l2_loss(y_hatV, y_val, alpha).item()))\n",
    "\n",
    "        # k-space metrics on full prediction & val mask\n",
    "        y_hat_full = A(x, torch.ones_like(m_val), sens)  # (C,X,Y,Z)\n",
    "        y_true     = ksp[p]                              # (C,X,Y,Z)\n",
    "        omse, oce  = kspace_metrics(y_hat_full, y_true, m_val)  # uses your helper\n",
    "        omse_list.append(omse)\n",
    "        oce_list.append(oce)\n",
    "\n",
    "    val_loss = float(np.mean(losses)) if losses else float('nan')\n",
    "    return val_loss, float(np.mean(omse_list)), float(np.mean(oce_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a6b1d93-9e6e-47a5-854e-1379653529e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_optimizer_and_warmcos_scheduler(\n",
    "    params,\n",
    "    total_epochs: int,\n",
    "    warmup_epochs: int = 3,\n",
    "    lr_start: float = 5e-4,\n",
    "    lr_min: float = 5e-6,\n",
    "    warmup_start_factor: float = 0.2,\n",
    "):\n",
    "    \"\"\"\n",
    "    Linear warmup for `warmup_epochs`, then cosine anneal to `lr_min`.\n",
    "    Returns: (optimizer, scheduler)\n",
    "    \"\"\"\n",
    "    opt = torch.optim.Adam(params, lr=lr_start)\n",
    "\n",
    "    sched_warm = torch.optim.lr_scheduler.LinearLR(\n",
    "        opt, start_factor=warmup_start_factor, total_iters=warmup_epochs\n",
    "    )\n",
    "    sched_cos = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "        opt, T_max=max(1, total_epochs - warmup_epochs), eta_min=lr_min\n",
    "    )\n",
    "    scheduler = torch.optim.lr_scheduler.SequentialLR(\n",
    "        opt, schedulers=[sched_warm, sched_cos], milestones=[warmup_epochs]\n",
    "    )\n",
    "    return opt, scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b83d88d-554a-40b4-a158-259e962c1f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_lambda_schedule(\n",
    "    T: int,\n",
    "    lam_max: float = 3e-2,\n",
    "    lam_min: float = 0.0,\n",
    "    warmup_epochs: int = 0,\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns a function lam_sched(epoch) that gives λ for that epoch.\n",
    "    Linear warmup to lam_max for `warmup_epochs`, then cosine decay to lam_min.\n",
    "    \"\"\"\n",
    "    T_cos = max(1, T - warmup_epochs)\n",
    "\n",
    "    def lam_sched(epoch: int) -> float:\n",
    "        if epoch < warmup_epochs:\n",
    "            # linear ramp 0 → lam_max\n",
    "            return lam_max * (epoch + 1) / max(1, warmup_epochs)\n",
    "        # cosine phase\n",
    "        t = epoch - warmup_epochs\n",
    "        cos_term = 0.5 * (1 + math.cos(math.pi * t / T_cos))\n",
    "        return lam_min + (lam_max - lam_min) * cos_term\n",
    "\n",
    "    return lam_sched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ece60038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch   0] train_Λ=4.639e-05  ‖∇‖=3.747e-03  val=3.564e-06  (Ω_MSE=4.556e-06, Ωc_E=1.151e-04)  λ=3.00e-02 LR=2.3e-04  time=105.5s\n",
      "[Epoch   1] train_Λ=1.069e-05  ‖∇‖=9.434e-04  val=1.791e-06  (Ω_MSE=1.147e-06, Ωc_E=2.976e-05)  λ=3.00e-02 LR=3.7e-04  time=105.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:198: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch   2] train_Λ=6.385e-06  ‖∇‖=7.658e-04  val=9.131e-07  (Ω_MSE=2.642e-07, Ωc_E=6.863e-06)  λ=2.99e-02 LR=5.0e-04  time=104.9s\n",
      "[Epoch   3] train_Λ=4.064e-06  ‖∇‖=6.272e-04  val=6.969e-07  (Ω_MSE=1.308e-07, Ωc_E=3.407e-06)  λ=2.98e-02 LR=5.0e-04  time=104.9s\n",
      "[Epoch   4] train_Λ=2.883e-06  ‖∇‖=4.957e-04  val=4.645e-07  (Ω_MSE=4.225e-08, Ωc_E=1.288e-06)  λ=2.97e-02 LR=5.0e-04  time=105.1s\n",
      "[Epoch   5] train_Λ=2.125e-06  ‖∇‖=3.960e-04  val=3.620e-07  (Ω_MSE=1.576e-08, Ωc_E=6.132e-07)  λ=2.95e-02 LR=5.0e-04  time=105.0s\n",
      "[Epoch   6] train_Λ=1.801e-06  ‖∇‖=3.754e-04  val=3.896e-07  (Ω_MSE=2.408e-08, Ωc_E=6.921e-07)  λ=2.93e-02 LR=4.9e-04  time=104.9s\n",
      "[Epoch   7] train_Λ=1.826e-06  ‖∇‖=4.187e-04  val=3.364e-07  (Ω_MSE=1.226e-08, Ωc_E=4.282e-07)  λ=2.90e-02 LR=4.9e-04  time=104.8s\n",
      "[Epoch   8] train_Λ=1.783e-06  ‖∇‖=4.613e-04  val=5.159e-07  (Ω_MSE=6.456e-08, Ωc_E=1.510e-06)  λ=2.87e-02 LR=4.9e-04  time=105.1s\n",
      "[Epoch   9] train_Λ=1.700e-06  ‖∇‖=4.073e-04  val=4.150e-07  (Ω_MSE=3.387e-08, Ωc_E=8.654e-07)  λ=2.84e-02 LR=4.8e-04  time=104.9s\n",
      "[Epoch  10] train_Λ=1.597e-06  ‖∇‖=4.014e-04  val=4.081e-07  (Ω_MSE=2.922e-08, Ωc_E=8.046e-07)  λ=2.80e-02 LR=4.8e-04  time=104.9s\n",
      "[Epoch  11] train_Λ=1.628e-06  ‖∇‖=4.333e-04  val=4.405e-07  (Ω_MSE=4.348e-08, Ωc_E=1.089e-06)  λ=2.76e-02 LR=4.7e-04  time=104.8s\n",
      "[Epoch  12] train_Λ=1.655e-06  ‖∇‖=4.315e-04  val=3.489e-07  (Ω_MSE=1.730e-08, Ωc_E=4.622e-07)  λ=2.71e-02 LR=4.6e-04  time=104.9s\n",
      "[Epoch  13] train_Λ=1.485e-06  ‖∇‖=3.451e-04  val=3.286e-07  (Ω_MSE=1.295e-08, Ωc_E=3.797e-07)  λ=2.67e-02 LR=4.6e-04  time=105.3s\n",
      "[Epoch  14] train_Λ=1.442e-06  ‖∇‖=3.837e-04  val=3.002e-07  (Ω_MSE=8.364e-09, Ωc_E=2.432e-07)  λ=2.61e-02 LR=4.5e-04  time=105.1s\n",
      "[Epoch  15] train_Λ=1.354e-06  ‖∇‖=3.204e-04  val=3.306e-07  (Ω_MSE=1.424e-08, Ωc_E=4.229e-07)  λ=2.56e-02 LR=4.4e-04  time=104.9s\n",
      "[Epoch  16] train_Λ=1.249e-06  ‖∇‖=2.875e-04  val=2.802e-07  (Ω_MSE=6.482e-09, Ωc_E=1.584e-07)  λ=2.50e-02 LR=4.3e-04  time=105.0s\n",
      "[Epoch  17] train_Λ=1.243e-06  ‖∇‖=2.811e-04  val=2.776e-07  (Ω_MSE=6.371e-09, Ωc_E=1.663e-07)  λ=2.44e-02 LR=4.2e-04  time=104.9s\n",
      "[Epoch  18] train_Λ=1.243e-06  ‖∇‖=2.983e-04  val=3.406e-07  (Ω_MSE=1.612e-08, Ωc_E=4.921e-07)  λ=2.38e-02 LR=4.1e-04  time=104.9s\n",
      "[Epoch  19] train_Λ=1.470e-06  ‖∇‖=4.160e-04  val=4.317e-07  (Ω_MSE=3.859e-08, Ωc_E=1.111e-06)  λ=2.32e-02 LR=4.0e-04  time=104.8s\n",
      "[Epoch  20] train_Λ=1.839e-06  ‖∇‖=4.730e-04  val=2.628e-07  (Ω_MSE=4.604e-09, Ωc_E=1.279e-07)  λ=2.25e-02 LR=3.9e-04  time=105.0s\n",
      "[Epoch  21] train_Λ=1.243e-06  ‖∇‖=2.955e-04  val=3.092e-07  (Ω_MSE=1.146e-08, Ωc_E=3.298e-07)  λ=2.18e-02 LR=3.8e-04  time=104.9s\n",
      "[Epoch  22] train_Λ=1.232e-06  ‖∇‖=2.992e-04  val=2.583e-07  (Ω_MSE=4.524e-09, Ωc_E=1.137e-07)  λ=2.11e-02 LR=3.6e-04  time=104.9s\n",
      "[Epoch  23] train_Λ=1.307e-06  ‖∇‖=3.394e-04  val=2.973e-07  (Ω_MSE=9.239e-09, Ωc_E=2.929e-07)  λ=2.04e-02 LR=3.5e-04  time=104.9s\n",
      "[Epoch  24] train_Λ=1.181e-06  ‖∇‖=2.812e-04  val=2.619e-07  (Ω_MSE=4.923e-09, Ωc_E=1.381e-07)  λ=1.96e-02 LR=3.4e-04  time=105.0s\n",
      "[Epoch  25] train_Λ=1.083e-06  ‖∇‖=1.538e-04  val=2.645e-07  (Ω_MSE=5.422e-09, Ωc_E=1.474e-07)  λ=1.89e-02 LR=3.3e-04  time=105.1s\n",
      "[Epoch  26] train_Λ=1.118e-06  ‖∇‖=2.199e-04  val=2.637e-07  (Ω_MSE=5.684e-09, Ωc_E=1.547e-07)  λ=1.81e-02 LR=3.1e-04  time=104.9s\n",
      "[Epoch  27] train_Λ=1.155e-06  ‖∇‖=2.712e-04  val=2.438e-07  (Ω_MSE=3.390e-09, Ωc_E=8.777e-08)  λ=1.73e-02 LR=3.0e-04  time=104.9s\n",
      "[Epoch  28] train_Λ=1.062e-06  ‖∇‖=1.453e-04  val=2.395e-07  (Ω_MSE=3.092e-09, Ωc_E=8.046e-08)  λ=1.66e-02 LR=2.9e-04  time=104.9s\n",
      "[Epoch  29] train_Λ=1.063e-06  ‖∇‖=1.564e-04  val=2.426e-07  (Ω_MSE=3.505e-09, Ωc_E=9.368e-08)  λ=1.58e-02 LR=2.7e-04  time=104.9s\n",
      "[Epoch  30] train_Λ=1.053e-06  ‖∇‖=1.464e-04  val=2.347e-07  (Ω_MSE=2.768e-09, Ωc_E=7.724e-08)  λ=1.50e-02 LR=2.6e-04  time=104.9s\n",
      "[Epoch  31] train_Λ=1.049e-06  ‖∇‖=1.355e-04  val=2.341e-07  (Ω_MSE=2.735e-09, Ωc_E=8.660e-08)  λ=1.42e-02 LR=2.5e-04  time=104.9s\n",
      "[Epoch  32] train_Λ=1.058e-06  ‖∇‖=1.592e-04  val=2.302e-07  (Ω_MSE=2.568e-09, Ωc_E=7.437e-08)  λ=1.34e-02 LR=2.3e-04  time=105.0s\n",
      "[Epoch  33] train_Λ=1.076e-06  ‖∇‖=1.782e-04  val=2.331e-07  (Ω_MSE=2.754e-09, Ωc_E=9.641e-08)  λ=1.27e-02 LR=2.2e-04  time=104.9s\n",
      "[Epoch  34] train_Λ=1.036e-06  ‖∇‖=1.053e-04  val=2.319e-07  (Ω_MSE=2.798e-09, Ωc_E=9.334e-08)  λ=1.19e-02 LR=2.1e-04  time=104.8s\n",
      "[Epoch  35] train_Λ=1.049e-06  ‖∇‖=1.304e-04  val=2.240e-07  (Ω_MSE=2.277e-09, Ωc_E=7.460e-08)  λ=1.11e-02 LR=1.9e-04  time=104.9s\n",
      "[Epoch  36] train_Λ=1.048e-06  ‖∇‖=1.252e-04  val=2.377e-07  (Ω_MSE=3.604e-09, Ωc_E=1.333e-07)  λ=1.04e-02 LR=1.8e-04  time=104.9s\n",
      "[Epoch  37] train_Λ=1.056e-06  ‖∇‖=1.362e-04  val=2.195e-07  (Ω_MSE=2.133e-09, Ωc_E=7.192e-08)  λ=9.62e-03 LR=1.7e-04  time=104.9s\n",
      "[Epoch  38] train_Λ=1.040e-06  ‖∇‖=8.829e-05  val=2.193e-07  (Ω_MSE=2.154e-09, Ωc_E=7.992e-08)  λ=8.90e-03 LR=1.5e-04  time=105.0s\n",
      "[Epoch  39] train_Λ=1.053e-06  ‖∇‖=1.059e-04  val=2.286e-07  (Ω_MSE=2.906e-09, Ωc_E=1.382e-07)  λ=8.19e-03 LR=1.4e-04  time=104.9s\n",
      "[Epoch  40] train_Λ=1.072e-06  ‖∇‖=1.228e-04  val=2.155e-07  (Ω_MSE=2.046e-09, Ωc_E=8.232e-08)  λ=7.50e-03 LR=1.3e-04  time=105.0s\n",
      "[Epoch  41] train_Λ=1.053e-06  ‖∇‖=7.301e-05  val=2.113e-07  (Ω_MSE=1.909e-09, Ωc_E=7.474e-08)  λ=6.83e-03 LR=1.2e-04  time=104.9s\n",
      "[Epoch  42] train_Λ=1.047e-06  ‖∇‖=3.675e-05  val=2.082e-07  (Ω_MSE=1.780e-09, Ωc_E=7.406e-08)  λ=6.18e-03 LR=1.1e-04  time=105.0s\n",
      "[Epoch  43] train_Λ=1.049e-06  ‖∇‖=2.356e-05  val=2.059e-07  (Ω_MSE=1.721e-09, Ωc_E=7.533e-08)  λ=5.56e-03 LR=9.5e-05  time=104.9s\n",
      "[Epoch  44] train_Λ=1.051e-06  ‖∇‖=2.511e-05  val=2.032e-07  (Ω_MSE=1.653e-09, Ωc_E=7.451e-08)  λ=4.96e-03 LR=8.5e-05  time=104.9s\n",
      "[Epoch  45] train_Λ=1.048e-06  ‖∇‖=2.341e-05  val=2.007e-07  (Ω_MSE=1.594e-09, Ωc_E=7.652e-08)  λ=4.39e-03 LR=7.5e-05  time=105.0s\n",
      "[Epoch  46] train_Λ=1.043e-06  ‖∇‖=1.025e-05  val=1.977e-07  (Ω_MSE=1.523e-09, Ωc_E=7.702e-08)  λ=3.85e-03 LR=6.6e-05  time=104.8s\n",
      "[Epoch  47] train_Λ=1.039e-06  ‖∇‖=1.159e-05  val=1.948e-07  (Ω_MSE=1.461e-09, Ωc_E=7.877e-08)  λ=3.34e-03 LR=5.7e-05  time=104.9s\n",
      "[Epoch  48] train_Λ=1.036e-06  ‖∇‖=8.595e-06  val=1.916e-07  (Ω_MSE=1.389e-09, Ωc_E=8.222e-08)  λ=2.86e-03 LR=4.9e-05  time=104.9s\n",
      "[Epoch  49] train_Λ=1.034e-06  ‖∇‖=5.797e-06  val=1.882e-07  (Ω_MSE=1.325e-09, Ωc_E=8.355e-08)  λ=2.42e-03 LR=4.2e-05  time=105.0s\n",
      "[Epoch  50] train_Λ=1.032e-06  ‖∇‖=3.775e-06  val=1.847e-07  (Ω_MSE=1.259e-09, Ωc_E=8.691e-08)  λ=2.01e-03 LR=3.5e-05  time=104.9s\n",
      "[Epoch  51] train_Λ=1.031e-06  ‖∇‖=3.078e-06  val=1.807e-07  (Ω_MSE=1.192e-09, Ωc_E=8.973e-08)  λ=1.63e-03 LR=2.9e-05  time=105.0s\n",
      "[Epoch  52] train_Λ=1.030e-06  ‖∇‖=2.358e-06  val=1.765e-07  (Ω_MSE=1.123e-09, Ωc_E=9.403e-08)  λ=1.30e-03 LR=2.3e-05  time=104.9s\n",
      "[Epoch  53] train_Λ=1.029e-06  ‖∇‖=1.832e-06  val=1.716e-07  (Ω_MSE=1.051e-09, Ωc_E=9.925e-08)  λ=9.96e-04 LR=1.8e-05  time=105.0s\n",
      "[Epoch  54] train_Λ=1.028e-06  ‖∇‖=1.395e-06  val=1.659e-07  (Ω_MSE=9.736e-10, Ωc_E=1.066e-07)  λ=7.34e-04 LR=1.4e-05  time=104.9s\n",
      "[Epoch  55] train_Λ=1.028e-06  ‖∇‖=1.013e-06  val=1.606e-07  (Ω_MSE=9.061e-10, Ωc_E=1.138e-07)  λ=5.11e-04 LR=1.1e-05  time=104.9s\n",
      "[Epoch  56] train_Λ=1.028e-06  ‖∇‖=6.846e-07  val=1.601e-07  (Ω_MSE=9.000e-10, Ωc_E=1.092e-07)  λ=3.28e-04 LR=8.4e-06  time=104.8s\n",
      "[Epoch  57] train_Λ=1.028e-06  ‖∇‖=4.065e-07  val=1.601e-07  (Ω_MSE=8.990e-10, Ωc_E=1.062e-07)  λ=1.85e-04 LR=6.5e-06  time=104.9s\n",
      "[Epoch  58] train_Λ=1.028e-06  ‖∇‖=1.899e-07  val=1.599e-07  (Ω_MSE=8.973e-10, Ωc_E=1.054e-07)  λ=8.22e-05 LR=5.4e-06  time=104.8s\n",
      "[Epoch  59] train_Λ=1.028e-06  ‖∇‖=4.911e-08  val=1.599e-07  (Ω_MSE=8.968e-10, Ωc_E=1.056e-07)  λ=2.06e-05 LR=5.0e-06  time=104.8s\n"
     ]
    }
   ],
   "source": [
    "# --- hyperparams ---\n",
    "epochs       = 60\n",
    "K            = 3                 # neighbors on each side → in_ch = 2*K + 2\n",
    "unroll_tr    = 5\n",
    "unroll_val   = 5\n",
    "cg_tr_iters  = 8\n",
    "cg_val_iters = 25\n",
    "cg_tol_tr    = 1e-6\n",
    "cg_tol_val   = 1e-6\n",
    "alpha        = 0.5               # L1/L2 mix in k-space loss\n",
    "lam          = 3e-2              # data-consistency weight (fixed for now)\n",
    "\n",
    "# --- model & optim ---\n",
    "prior = Pseudo3DUNet2p5D(in_ch=2*K + 2, base=32, out_ch=2, residual_scale=0.1).to(ksp_t.device)\n",
    "\n",
    "opt, scheduler = make_optimizer_and_warmcos_scheduler(\n",
    "    prior.parameters(), total_epochs=epochs, warmup_epochs=3, lr_start=5e-4, lr_min=5e-6\n",
    ")\n",
    "\n",
    "lam_sched = make_lambda_schedule(T=epochs, lam_max=lam, lam_min=0.0, warmup_epochs=0)\n",
    "\n",
    "best_val = float('inf')\n",
    "\n",
    "def save_ckpt(path, epoch, val_loss, model, opt):\n",
    "    torch.save({\n",
    "        \"epoch\": epoch,\n",
    "        \"val_loss\": float(val_loss),\n",
    "        \"model_state\": model.state_dict(),\n",
    "        \"opt_state\": opt.state_dict(),\n",
    "    }, path)\n",
    "\n",
    "for ep in range(epochs):\n",
    "    t0 = time.time()\n",
    "    lam = lam_sched(ep)\n",
    "\n",
    "    # ---- one epoch of training ----\n",
    "    tr = train_one_epoch_cued(\n",
    "        prior, opt,\n",
    "        ksp_t, sens_t, bmasks, cues_2d,\n",
    "        A, AH, solve_cg, apply_prior_25d_cued, kspace_l1_l2_loss,\n",
    "        lam=lam, K=K,\n",
    "        unroll=unroll_tr, cg_iters=cg_tr_iters, cg_tol=cg_tol_tr,\n",
    "        alpha=alpha, device=ksp_t.device.type\n",
    "    )\n",
    "\n",
    "    # ---- validation ----\n",
    "    vL, v_omse, v_oce = validate_all_phases_cued(\n",
    "        prior,\n",
    "        ksp_t, sens_t, bmasks, cues_2d,\n",
    "        A, AH, solve_cg, apply_prior_25d_cued, kspace_l1_l2_loss, kspace_metrics,\n",
    "        lam=lam, K=K,\n",
    "        unroll=unroll_val, cg_iters=cg_val_iters, cg_tol=cg_tol_val,\n",
    "        alpha=alpha\n",
    "    )\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    # ---- ckpts ----\n",
    "    save_ckpt(\"latest_cued_prior.pt\", ep+1, vL, prior, opt)\n",
    "    if vL < best_val - 1e-9:\n",
    "        best_val = vL\n",
    "        save_ckpt(\"best_cued_prior.pt\", ep+1, vL, prior, opt)\n",
    "\n",
    "    dt = time.time() - t0\n",
    "    print(f\"[Epoch {ep:3d}] train_Λ={tr['train_L']:.3e}  ‖∇‖={tr['grad']:.3e}  \"\n",
    "          f\"val={vL:.3e}  (Ω_MSE={v_omse:.3e}, Ωc_E={v_oce:.3e})  \"\n",
    "          f\"λ={lam:.2e} LR={opt.param_groups[0]['lr']:.1e}  time={dt:.1f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1de8e55a-663c-4f30-b3a4-e48c6fb6e3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def infer_and_save_all_phases_cued(\n",
    "    prior, ksp_t, sens_t, bmasks, cues_2d,\n",
    "    K=3, lam=1e-2, unroll=5, cg_iters=25, cg_tol=1e-6,\n",
    "    out_dir=\"infer_cued\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Saves: out_dir/phase_XX_recon_img.npy  (complex image volume, shape: (X,Y,Z))\n",
    "    \"\"\"\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    prior.eval()\n",
    "    P = ksp_t.shape[0]\n",
    "\n",
    "    for p in range(P):\n",
    "        y      = ksp_t[p]               # (C,X,Y,Z) complex\n",
    "        S      = sens_t                 # (C,X,Y,Z) complex\n",
    "        m_yz   = bmasks[\"omega\"][p]     # (1,1,Y,Z)\n",
    "        cues_p = cues_2d[p]             # (2,Y,Z) float\n",
    "\n",
    "        # CG-SENSE init\n",
    "        rhs = AH(y, m_yz, S)\n",
    "        x   = solve_cg(rhs, m_yz, S, lam, iters=cg_iters, tol=cg_tol, x0=rhs)\n",
    "\n",
    "        # Unroll\n",
    "        for _ in range(unroll):\n",
    "            r   = apply_prior_25d_cued(prior, x, cues_p, K)   # (X,Y,Z) complex\n",
    "            x_t = x + r\n",
    "            b   = rhs + lam * x_t\n",
    "            x   = solve_cg(b, m_yz, S, lam, iters=cg_iters, tol=cg_tol, x0=None)\n",
    "\n",
    "        # Metrics over Ω for logging only\n",
    "        y_hat = A(x, m_yz, S)\n",
    "        omse, oce = kspace_metrics(y_hat, y, m_yz)\n",
    "        print(f\"[phase {p+1:02d}] Ω_MSE={omse:.3e}  Ωc_E={oce:.3e}\")\n",
    "\n",
    "        # Save complex image volume\n",
    "        out_path = os.path.join(out_dir, f\"phase_{p+1:02d}_recon_img.npy\")\n",
    "        np.save(out_path, x.detach().cpu().numpy())\n",
    "        print(f\"Saved → {out_path}\")\n",
    "\n",
    "    print(f\"Done. Per-phase recons saved in: {out_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9992080b-dde6-4aa1-a4e9-9b582d795893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[phase 01] Ω_MSE=3.097e-09  Ωc_E=0.000e+00\n",
      "Saved → infer_cued/phase_01_recon_img.npy\n",
      "[phase 02] Ω_MSE=3.426e-09  Ωc_E=0.000e+00\n",
      "Saved → infer_cued/phase_02_recon_img.npy\n",
      "[phase 03] Ω_MSE=3.141e-09  Ωc_E=0.000e+00\n",
      "Saved → infer_cued/phase_03_recon_img.npy\n",
      "[phase 04] Ω_MSE=3.981e-09  Ωc_E=0.000e+00\n",
      "Saved → infer_cued/phase_04_recon_img.npy\n",
      "[phase 05] Ω_MSE=2.554e-09  Ωc_E=0.000e+00\n",
      "Saved → infer_cued/phase_05_recon_img.npy\n",
      "[phase 06] Ω_MSE=3.652e-09  Ωc_E=0.000e+00\n",
      "Saved → infer_cued/phase_06_recon_img.npy\n",
      "[phase 07] Ω_MSE=2.868e-09  Ωc_E=0.000e+00\n",
      "Saved → infer_cued/phase_07_recon_img.npy\n",
      "[phase 08] Ω_MSE=3.153e-09  Ωc_E=0.000e+00\n",
      "Saved → infer_cued/phase_08_recon_img.npy\n",
      "[phase 09] Ω_MSE=2.785e-09  Ωc_E=0.000e+00\n",
      "Saved → infer_cued/phase_09_recon_img.npy\n",
      "[phase 10] Ω_MSE=3.753e-09  Ωc_E=0.000e+00\n",
      "Saved → infer_cued/phase_10_recon_img.npy\n",
      "[phase 11] Ω_MSE=2.750e-09  Ωc_E=0.000e+00\n",
      "Saved → infer_cued/phase_11_recon_img.npy\n",
      "[phase 12] Ω_MSE=3.598e-09  Ωc_E=0.000e+00\n",
      "Saved → infer_cued/phase_12_recon_img.npy\n",
      "[phase 13] Ω_MSE=3.166e-09  Ωc_E=0.000e+00\n",
      "Saved → infer_cued/phase_13_recon_img.npy\n",
      "[phase 14] Ω_MSE=3.203e-09  Ωc_E=0.000e+00\n",
      "Saved → infer_cued/phase_14_recon_img.npy\n",
      "[phase 15] Ω_MSE=3.118e-09  Ωc_E=0.000e+00\n",
      "Saved → infer_cued/phase_15_recon_img.npy\n",
      "[phase 16] Ω_MSE=3.156e-09  Ωc_E=0.000e+00\n",
      "Saved → infer_cued/phase_16_recon_img.npy\n",
      "[phase 17] Ω_MSE=3.234e-09  Ωc_E=0.000e+00\n",
      "Saved → infer_cued/phase_17_recon_img.npy\n",
      "[phase 18] Ω_MSE=2.954e-09  Ωc_E=0.000e+00\n",
      "Saved → infer_cued/phase_18_recon_img.npy\n",
      "[phase 19] Ω_MSE=3.098e-09  Ωc_E=0.000e+00\n",
      "Saved → infer_cued/phase_19_recon_img.npy\n",
      "[phase 20] Ω_MSE=2.845e-09  Ωc_E=0.000e+00\n",
      "Saved → infer_cued/phase_20_recon_img.npy\n",
      "Done. Per-phase recons saved in: infer_cued\n"
     ]
    }
   ],
   "source": [
    "# ---- config (match training) ----\n",
    "K        = 3\n",
    "IN_CH    = 2*K + 2          # 2K (re/im neighbors) + 2 (sin,cos)\n",
    "UNROLL   = 5\n",
    "CG_ITERS = 25\n",
    "CG_TOL   = 1e-6\n",
    "LAM_DC   = 1e-6             # data-consistency λ\n",
    "OUT_DIR  = \"infer_cued\"\n",
    "DEVICE   = ksp_t.device\n",
    "\n",
    "# ---- model: build + load best checkpoint ----\n",
    "prior = Pseudo3DUNet2p5D(in_ch=IN_CH, base=32, out_ch=2, residual_scale=0.1).to(DEVICE).eval()\n",
    "ckpt   = torch.load(\"best_cued_prior.pt\", map_location=DEVICE)\n",
    "state  = ckpt.get(\"model_state\", ckpt.get(\"state_dict\", ckpt))\n",
    "prior.load_state_dict(state, strict=False)\n",
    "\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "P = ksp_t.shape[0]\n",
    "\n",
    "infer_and_save_all_phases_cued(\n",
    "    prior, ksp_t, sens_t, bmasks, cues_2d,\n",
    "    K=K, lam=LAM_DC, unroll=UNROLL,\n",
    "    cg_iters=CG_ITERS, cg_tol=CG_TOL,\n",
    "    out_dir=OUT_DIR\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "napari-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
